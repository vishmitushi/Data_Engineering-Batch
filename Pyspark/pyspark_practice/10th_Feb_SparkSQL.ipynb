{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8589c9b6-5c08-41ea-b007-699f20820295",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark \n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Spark_SQL Operations').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8413d6e8-2e4f-4585-98bb-d549169f633d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+---------------+------+-------------+------------------+----------------+---------------+------------+----------------+------------+\n|work_year|           job_title|        job_category|salary_currency|salary|salary_in_usd|employee_residence|experience_level|employment_type|work_setting|company_location|company_size|\n+---------+--------------------+--------------------+---------------+------+-------------+------------------+----------------+---------------+------------+----------------+------------+\n|     2023|Data DevOps Engineer|    Data Engineering|            EUR| 88000|        95012|           Germany|       Mid-level|      Full-time|      Hybrid|         Germany|           L|\n|     2023|      Data Architect|Data Architecture...|            USD|186000|       186000|     United States|          Senior|      Full-time|   In-person|   United States|           M|\n|     2023|      Data Architect|Data Architecture...|            USD| 81800|        81800|     United States|          Senior|      Full-time|   In-person|   United States|           M|\n|     2023|      Data Scientist|Data Science and ...|            USD|212000|       212000|     United States|          Senior|      Full-time|   In-person|   United States|           M|\n|     2023|      Data Scientist|Data Science and ...|            USD| 93300|        93300|     United States|          Senior|      Full-time|   In-person|   United States|           M|\n|     2023|      Data Scientist|Data Science and ...|            USD|130000|       130000|     United States|          Senior|      Full-time|      Remote|   United States|           M|\n|     2023|      Data Scientist|Data Science and ...|            USD|100000|       100000|     United States|          Senior|      Full-time|      Remote|   United States|           M|\n|     2023|Machine Learning ...|Machine Learning ...|            USD|224400|       224400|     United States|       Mid-level|      Full-time|   In-person|   United States|           M|\n|     2023|Machine Learning ...|Machine Learning ...|            USD|138700|       138700|     United States|       Mid-level|      Full-time|   In-person|   United States|           M|\n|     2023|       Data Engineer|    Data Engineering|            USD|210000|       210000|     United States|       Executive|      Full-time|      Remote|   United States|           M|\n|     2023|       Data Engineer|    Data Engineering|            USD|168000|       168000|     United States|       Executive|      Full-time|      Remote|   United States|           M|\n|     2023|Machine Learning ...|Machine Learning ...|            USD|224400|       224400|     United States|          Senior|      Full-time|   In-person|   United States|           M|\n|     2023|Machine Learning ...|Machine Learning ...|            USD|138700|       138700|     United States|          Senior|      Full-time|   In-person|   United States|           M|\n|     2023|      Data Scientist|Data Science and ...|            GBP| 35000|        43064|    United Kingdom|       Mid-level|      Full-time|   In-person|  United Kingdom|           M|\n|     2023|      Data Scientist|Data Science and ...|            GBP| 30000|        36912|    United Kingdom|       Mid-level|      Full-time|   In-person|  United Kingdom|           M|\n|     2023|        Data Analyst|       Data Analysis|            USD| 95000|        95000|     United States|     Entry-level|      Full-time|   In-person|   United States|           M|\n|     2023|        Data Analyst|       Data Analysis|            USD| 75000|        75000|     United States|     Entry-level|      Full-time|   In-person|   United States|           M|\n|     2023|      Data Scientist|Data Science and ...|            USD|300000|       300000|     United States|          Senior|      Full-time|   In-person|   United States|           M|\n|     2023|      Data Scientist|Data Science and ...|            USD|234000|       234000|     United States|          Senior|      Full-time|   In-person|   United States|           M|\n+---------+--------------------+--------------------+---------------+------+-------------+------------------+----------------+---------------+------------+----------------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('/FileStore/tables/table1/jobs_in_data.csv',header=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1cd42ed-5469-41e2-8c41-a74a289b5abe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"sampleView\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a1a5bf4-49a9-49a0-b768-cc1367c06ee4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[20]: DataFrame[work_year: string, job_title: string, job_category: string, salary_currency: string, salary: string, salary_in_usd: string, employee_residence: string, experience_level: string, employment_type: string, work_setting: string, company_location: string, company_size: string]"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * from sampleView\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a88fb6d7-da30-420a-9b8d-c07a808c76ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+------+\n|year|               title|salary|\n+----+--------------------+------+\n|2023|Data DevOps Engineer| 88000|\n|2023|      Data Architect|186000|\n|2023|      Data Architect| 81800|\n|2023|      Data Scientist|212000|\n|2023|      Data Scientist| 93300|\n|2023|      Data Scientist|130000|\n|2023|      Data Scientist|100000|\n|2023|Machine Learning ...|224400|\n|2023|Machine Learning ...|138700|\n|2023|       Data Engineer|210000|\n|2023|       Data Engineer|168000|\n|2023|Machine Learning ...|224400|\n|2023|Machine Learning ...|138700|\n|2023|      Data Scientist| 35000|\n|2023|      Data Scientist| 30000|\n|2023|        Data Analyst| 95000|\n|2023|        Data Analyst| 75000|\n|2023|      Data Scientist|300000|\n|2023|      Data Scientist|234000|\n+----+--------------------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# Create a Database CT\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS Test\")\n",
    " \n",
    "# Create a Table naming as sampleTable under CT database.\n",
    "spark.sql(\"CREATE TABLE Test.sampleTable1 (year Int, title String, salary INT)\")\n",
    " \n",
    "# Insert into sampleTable using the sampleView.\n",
    "spark.sql(\"INSERT INTO TABLE Test.sampleTable1  SELECT work_year,job_title,salary FROM sampleView\")\n",
    " \n",
    "# Lets view the data in the table\n",
    "spark.sql(\"SELECT * FROM Test.sampleTable1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eecb1e8c-b196-467f-a89a-56ca836653db",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[9]: DataFrame[num_affected_rows: bigint]"
     ]
    }
   ],
   "source": [
    "spark.sql(\"UPDATE Test.sampleTable1 set year=2024 WHERE salary>150000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67669fe0-95e8-476d-b815-eb61280925bb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+------+\n|year|               title|salary|\n+----+--------------------+------+\n|2023|Data DevOps Engineer| 88000|\n|2024|      Data Architect|186000|\n|2023|      Data Architect| 81800|\n|2024|      Data Scientist|212000|\n|2023|      Data Scientist| 93300|\n|2023|      Data Scientist|130000|\n|2023|      Data Scientist|100000|\n|2024|Machine Learning ...|224400|\n|2023|Machine Learning ...|138700|\n|2024|       Data Engineer|210000|\n|2024|       Data Engineer|168000|\n|2024|Machine Learning ...|224400|\n|2023|Machine Learning ...|138700|\n|2023|      Data Scientist| 35000|\n|2023|      Data Scientist| 30000|\n|2023|        Data Analyst| 95000|\n|2023|        Data Analyst| 75000|\n|2024|      Data Scientist|300000|\n|2024|      Data Scientist|234000|\n+----+--------------------+------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM Test.sampleTable1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffc2b6b3-25bf-4a62-b53f-82d730a8364b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[27]: DataFrame[]"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DROP TABLE Test.sampleTable\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "10th_Feb_SparkSQL",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
