{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e488f42-4772-473b-bac8-474a27c42e8d",
     "showTitle": false,
     "title": ""
    },
    "id": "SjqZqOQe8ilD"
   },
   "outputs": [],
   "source": [
    "storage_account_name = \"adls1046project\"\n",
    "container_name = \"container\"\n",
    "file_name = \"GlobalLandTemperaturesByCountry.csv\"\n",
    "storage_account_access_key = \"KUKAhIfCYt/M/1Co79hLgWIsSzICBxQ7TJQ3s7DwtrO1gZWe/lRA0Rh43+Qmu1+PR31WfvqtRx6w+ASthC5Ofg==\"\n",
    "spark.conf.set(\"fs.azure.account.key.\" + storage_account_name + \".blob.core.windows.net\", storage_account_access_key)\n",
    "data = spark.read.format(\"csv\").load(f\"wasbs://{container_name}@{storage_account_name}.blob.core.windows.net/{file_name}\", inferSchema=True, header=True)\n",
    "\n",
    "# Register the DataFrame as a SQL temporary view\n",
    "data.createOrReplaceTempView(\"climate_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "123305c0-6333-4088-9948-2a4b59e8448a",
     "showTitle": false,
     "title": ""
    },
    "id": "u93NUKME8ilG",
    "outputId": "ef7913a4-c248-4d8f-cdfd-150d012b647b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema of the dataset:\nroot\n |-- Date: date (nullable = true)\n |-- AverageTemperature: double (nullable = true)\n |-- AverageTemperatureUncertainty: double (nullable = true)\n |-- Country: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# Identify the structure and schema of the dataset\n",
    "print(\"Schema of the dataset:\")\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13ca817a-067d-4da6-9563-b1fab02c663f",
     "showTitle": false,
     "title": ""
    },
    "id": "wX6OJI7_8ilH",
    "outputId": "c4bbe823-ee63-49fd-c5d7-661fd7506d7c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic statistics of numerical columns:\n+-------+------------------+-----------------------------+-----------+\n|summary|AverageTemperature|AverageTemperatureUncertainty|    Country|\n+-------+------------------+-----------------------------+-----------+\n|  count|            544811|                       545550|     577462|\n|   mean| 17.19335423293594|           1.0190569003757632|       NULL|\n| stddev|10.953966445121155|            1.201930386633437|       NULL|\n|    min|           -37.658|         0.052000000000000005|Afghanistan|\n|    max| 38.84200000000001|                       15.003|      Åland|\n+-------+------------------+-----------------------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Display basic statistics of numerical columns\n",
    "print(\"Basic statistics of numerical columns:\")\n",
    "data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82273c5a-69f1-4ac7-aa5f-8267ca60f824",
     "showTitle": false,
     "title": ""
    },
    "id": "hXgR1PS-8ilI",
    "outputId": "b82715e9-95a4-4042-ad44-45c554fe0bcd"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in the dataset: 577462\n"
     ]
    }
   ],
   "source": [
    "# Use Spark SQL queries to explore the data\n",
    "# Example 1: Count the number of records in the dataset\n",
    "record_count = spark.sql(\"SELECT COUNT(*) AS record_count FROM climate_data\").collect()[0][\"record_count\"]\n",
    "print(\"Number of records in the dataset:\", record_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d668f563-3e36-45bf-8ffb-51a44c1f6ed5",
     "showTitle": false,
     "title": ""
    },
    "id": "wOdggqoT8ilJ",
    "outputId": "ad866f0c-8a7e-49c2-ba09-ff3b8c93e694"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n+----------+------------------+-----------------------------+-------+\n|      Date|AverageTemperature|AverageTemperatureUncertainty|Country|\n+----------+------------------+-----------------------------+-------+\n|1743-11-01|4.3839999999999995|                        2.294|  Åland|\n|1743-12-01|              NULL|                         NULL|  Åland|\n|1744-01-01|              NULL|                         NULL|  Åland|\n|1744-02-01|              NULL|                         NULL|  Åland|\n|1744-03-01|              NULL|                         NULL|  Åland|\n+----------+------------------+-----------------------------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Show the first few rows of the dataset\n",
    "print(\"First few rows of the dataset:\")\n",
    "spark.sql(\"SELECT * FROM climate_data LIMIT 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae063621-6322-403f-a8e5-bf5efa1493e9",
     "showTitle": false,
     "title": ""
    },
    "id": "Z9s7siDz8ilK",
    "outputId": "91a5e1a0-177e-4f9b-ba7f-6f951ba4de47"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct Countries:\n+--------------+\n|       Country|\n+--------------+\n|      Anguilla|\n|         Åland|\n|   Afghanistan|\n|        Africa|\n|       Algeria|\n|     Argentina|\n|        Angola|\n|  Baker Island|\n|       Albania|\n|       Bahamas|\n|American Samoa|\n|       Andorra|\n|    Antarctica|\n|         Aruba|\n|    Azerbaijan|\n|       Armenia|\n|          Asia|\n|     Australia|\n|       Austria|\n|       Bahrain|\n+--------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Example 3: Display distinct values in a particular column\n",
    "print(\"Distinct Countries:\")\n",
    "spark.sql(\"SELECT DISTINCT Country FROM climate_data\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fe86985-f085-4c7b-9609-942d20306a2c",
     "showTitle": false,
     "title": ""
    },
    "id": "KwM2nGpa8ilL",
    "outputId": "17df2e8c-f673-4d63-e262-7ff84678d6c8"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average value of a of temperature of the year:\n+---------------------+------------------+\n|date_part(YEAR, Date)|          avg_temp|\n+---------------------+------------------+\n|                 1743|           5.18414|\n|                 1744|         9.8378975|\n|                 1745|1.3871250000000004|\n|                 1746|              NULL|\n|                 1747|              NULL|\n|                 1748|              NULL|\n|                 1749|              NULL|\n|                 1750| 9.129352727272728|\n|                 1751| 9.167387499999998|\n|                 1752| 4.413386666666668|\n|                 1753| 8.870820754716977|\n|                 1754| 8.822018957345971|\n|                 1755| 8.530536277602524|\n|                 1756|  9.17988625592417|\n|                 1757| 8.993332283464566|\n|                 1758|  8.13037054263566|\n|                 1759|  9.26125771604938|\n|                 1760|  8.53208176100629|\n|                 1761| 8.940669242658425|\n|                 1762| 8.517924148606811|\n+---------------------+------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Example 4: Calculate the average value of a numerical column\n",
    "print(\"Average value of a of temperature of the year:\")\n",
    "avg_temp = spark.sql(\"SELECT DATE_PART('YEAR', Date), AVG(AverageTemperature) AS avg_temp FROM climate_data GROUP BY DATE_PART('YEAR', Date) ORDER BY DATE_PART('YEAR', Date)\")\n",
    "avg_temp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fcea970a-d243-4385-85ac-47e738b5b51d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Data Exploration",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
